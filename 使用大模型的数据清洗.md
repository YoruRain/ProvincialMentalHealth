### 数据清洗-使用大模型

#### 1 微博采样

- 选取用户**最多20条**微博的文本作为分析依据
  - 20条微博 **按发布时间均匀采样** 得到
- 对于每条微博，仅截取**前200字**的内容
- 我认为通过 20条 的 最多200字 的微博已经足够大模型分析得出用户有效性，再增加内容有可能会消耗不必要的 Token



#### 2 大模型分析

- Prompt：

> 你是一名专业的社交媒体信息分析师，请根据用户发布的微博内容判断是否为生活分享账号，需满足以下至少2项特征：
>
> 1. 包含具体生活场景/人物互动/个人经历
> 2. 使用第一人称主观表达（如"我"的感受/经历）
> 3. 内容呈现非结构化自然叙述（非列表/教程/资讯格式）
> 4. 涉及日常活动（饮食/出行/家庭/宠物等）
>
> 需排除以下特征账号：
>
> - 垂直领域专业内容（医疗/法律/金融等）
> - 商品交易/广告推广信息
> - 抽象理论/鸡汤语录/政策转载
>
> 接下来我将给出一个JSON文件，其中键是用户ID，值是经过采样后的微博内容。
> 请直接为我返回**数字“0”或“1”**，“1”代表用户是生活分享账号，“0”代表用户不是生活分享账号。除此之外无需返回其他内容。

- 使用3个大模型的API：DeepSeek-v3、Qwen-Plus、Moonshot-v1
- 将3个模型得出的**分数之和**作为用户的最终分数，分数范围0~3分
- 0分可以断定是无效用户，3分可以断定是有效用户
- **人工审核得分为2分的用户**（这种情况下，3个模型中有2个模型认为是有价值的，可靠性比1分的更高）



#### 实际运行

- 实际分析96个用户后，分数分布为：
  - 0分：19人（清洗）
  - 1分：7人（清洗）
  - 2分：6人（人工审核）
  - 3分：64人（保留）
- 人工审核2分用户：

> ![image-20250501210242409](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20250501210242409.png)
>
> ![image-20250501210406330](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20250501210406330.png)
>
> ![image-20250501210442775](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20250501210442775.png)
>
> ![image-20250501210648623](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20250501210648623.png)
>
> ![image-20250501210936713](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20250501210936713.png)
>
> ![image-20250501211017978](C:\Users\admin\AppData\Roaming\Typora\typora-user-images\image-20250501211017978.png)

- 审核结果为6人全部保留，进入后续分析的数据集
- 分数列表中的顺序依次为 [DeepSeek, Qwen, Moonshot]，由上面的结果可以看出 **DeepSeek** 在判断用户有效性方面会**更加苛刻**
- 最终的有效用户比例为$(64+6) / 100=70\%$

